IndexAA/B testing for evaluation, 128, 280– 283absolute timestamps, 144abuse of notation, 202access to medical records thought ex‐periment, 323accuracy, 79, 97, 127accuracy of models, 315actors, 256actual errors, 65actual preferences, 210adding predictors, 69additive estimates, 156adjacency matrix, 264adversarial behavior, 242aggregate users, 141aggregating bootstraps, 190Akaike Information Criterion (AIC),183Aldhous, Peter, 175 algorithms, 51association, 356at scale, 89Basic Machine Learning Algo‐rithm Exercise, 85–89black box, 53clustering, 13, 82constraints on, 116–118 converged, 212evaluating models and, 318for wrapper feature selection, 181 Fruchterman-Reingold, 261 k-means, 81–91k-Nearest Neighbors (k-NN), 71–81linear regression, 55–71 machine learning, 52, 330 models vs., 56Allstate, 172alternating k-stars, 267 alternating least squares, 211 Amazon, 5, 308recommendation engines and, 199 Amazon Mechanical Turk, 169 ambient analytics, 247Amstat News, 8analytical applications Hadoop, 335MapReduce, 335Anderson, Chris, 27Apache Hive, 335Apache Software Foundation, 334www.finebook.ir361
APIs, warnings about, 107area under the cumulative lift curve,126area under the curve (AUC), 307goodness of, 301Artificial Artificial Intelligence, 169 Artificial Intelligence (AI), 52ASA, 8association algorithms, 356 associations, 60assumptions, 22explicit, 53attributes, predicting, 204 autocorrelation, 159–162automated statistician thought experi‐ment, 91 averages, 280Avro, 335 Bbackward elimination, 182 bagging, 190base, 207base rates, 121Basic Machine Learning Algorithm Exercise, 85–89Bayesian Information Criterion (BIC), 183, 205Beautiful Soup, 107Before Us is the Salesman’s House(Thorp/Hansen), 231–233 Bell Labs, 35Bernoulli model, 109 Bernoulli network, 266 betweenness, 258 bias-variance, 192 biases, 20, 21Big Data, 2, 4–6, 24 assumptions and, 24–26 defined, 24economic law, 334 Facebook and, 2Google and, 2objectivity of, 25 binary classes, 79Binder, Phillipe M., 45 bipartite graphs, 136, 257black box algorithms, 53 bootstrap aggregating, 190 bootstrap samples, 190 Bruner, Jon, 269–271Ccaret packages, 244case attribute vs. social network data,254causal effect, 287causal graphs, 286causal inference, 286causal models, 146–147, 146 causal questions, 274 causality, 273–289A/B testing for evaluation, 280– 283causal questions, 274clinical trials to determine, 279–280correlation vs., 274–276 observational studies and, 283–289OK Cupid example, 276–279 unit level, 285visualizing, 286–287centrality measures, 257–259 eigenvalue centrality, 264 usefulness of, 258channels, 325 problems with, 325chaos, 45chaos simulation thought experiment,44charity example, 319 checksums, 327 choosing classifiers, 115 classes, 119 classification, 54binary, 79 classifiers, 115–118choosing, 115 Naive Bayes, 339 spam, 119clear rates, 248 Cleveland, William, 9, 35 click models, 118362 | Indexwww.finebook.ir
clinical trials to determine causality, 279–280closeness, 75, 143, 257 Cloudera, 331, 334 clustering algorithms, 13, 82 clustering data, 81code samplesfor EDA, 38–40 RealDirect exercise, 49issues with, 167Kaggle and, 167 Mechanical Turks vs., 169 organization, 168 Wikipedia and, 167Cukier, Kenneth Neil, 5 Cukierski, William, 165 curves, goodness of, 301DDalessandro, Brian, 113 DARPA, 167dataabundance vs. scarcity, 332 clustering, 81extracting meaning from, 165–198 financial, preparing, 147–149 from the Web, 106–108geo-based location, 23 grouping, 81growing influence of, 4 images, 23in-sample, 146–147 labels, defining, 241 network, 23 normalizing, 148 objectivity of, 25 out-of-sample, 146–147 products, 5real-time streaming, 23 records, 23sensor, 23sparsity issues, 241 stratifying, 81text, 23traditional, 23 transforming, 148 types, 23web APIs for, 106–108data corpus, 21data engineering, 321–336data abundance vs. scarcity, 332 Hadoop and, 333–335 MapReduce, 324models, designing, 333Pregel, 331coding, 40cold stat problems, 241 computational complexity, 203 conditional distribution, 32 conditional entropy, 187 confidence intervals, 53 confounders, 275, 278correcting for, in practice, 295stratification and, 294–296 confusion matrix, 97 connected graphs, 257 constraints, on algorithmsat runtime, 116interpretability of, 117scalability, 117thought experiments for, 113–128 understanding, 117constructing features, 307continuous density function, 31 continuous variables in decision trees,188converged algorithms, 212 Conway, Drew, 7, 9correlated variables, 176 correlation vs. causality, 274–276 cosine similarity, 75, 202Cosma Shalizi, 8CountSketch, 329Crawford, Kate, 21Crawshaw, David, 322creating competitions, 166credit score example, 73–75 Cronkite Plaza (Thorp/Rubin/Hansen), 230 cross-validation, 67, 213 crowdsourcingDARPA and, 167 distributive, 167 InnoCentive and, 167www.finebook.irIndex | 363
word frequency problems, 325– 329workflow, 335data formats, 335data generating process, 304 data intuition, 274data journalism, 269–271writing, 270data leakage, 307–313avoiding, 313data preparation and, 311 merging databases and, 310 models that rely on, 308 predicting behavior based on cur‐rent data, 309predicting behavior based on his‐torical data, 308 sampling problems as, 309data mining competitions, 166, 305– 307creating, 166Kaggle and, 170Knowledge Discovery and DataMining (KDD), 166 data models, 26data munging, 7, 51data science, 1–16, 348–350available data for, 4–6Big Data and, 1–3careers in, 359chaos simulation thought experi‐ment, 44datafication, 5employment opportunities in, 9 Facebook and, 9Harvard Business Review, 8 history of, 6–10industry vs. academia in, 3 LinkedIn and, 9 meta-definition thought experi‐ment, 13privacy and, 196process of, 41–44 RealDirect case study, 46–49 scientific method and, 44 scientists, 10–13sociology and, 218teams, 11Venn diagram of, 7data science competitions, 166Kaggle and, 170 data scientists, 10–13as problem solvers, 350 chief, 304defining, 11ethics of, 354–355 female, 305hubris and, 355–358in academia, 14in industry, 15next generation of, 350–353 questioning as, 352role of, in data science process, 43soft skills of, 351data visualization, 217–250at Square, 247–248Before Us is the Salesman’s House(Thorp/Hansen), 231–233 Cronkite Plaza (Thorp/Rubin/Hansen), 230distant reading, 221fraud and, 236–239Hansen, Mark, 217–234history of, 217Lives on a Screen (Thorp/Hansen),229machine learning and, 235 Moveable Type (Rubin/Hansen),226–229personal data collection thoughtexperiment, 219 Processing programming lan‐guage, 221risk and, 234–248samples of, 222–226 Shakespeare Machine (Rubin/Hansen), 233 sociology and, 218 tutorials for, 249–250data visualization exercise, 250 data-generating processes, 19 DataEDGE, 242datafication, 4, 5DataKind, 355 datasetsfeature selection, 176–193364 | Indexwww.finebook.ir
keying, 58 sharding, 89 simulating, 70decay, 153, 155 decision treesDunning-Kruger effect, 352 dyads, 256, 266EeBay, 200, 207edges, 136, 256ego networks, 257Egyptian politics thought experiment,259eigenvalue centrality, 264social networks and, 264 electronic health records (EHR), 298,299embedded methods, 180 engaged users, 242 entropy, 183conditional, 187feature selection and, 186 specific conditional, 187epidemiology, 291–302academic statistics and, 293 confounders in, 294–296 Observational Medical OutcomesPartnership, 298–302 observational studies and, 293 observational studies, improvingon, 296–298 stratification and, 294–296Erdos-Renyi model graphs, 265–267 errors, 244actual, 65adding assumptions to models for,64–66defining metric of, 239in linear regression models, 64–66 mean absolute, 127mean squared, 66, 67, 127 measurement, 203observed, 66root squared, 127Essay Scoring Competition (Kaggle),173 estimators, 33, 63unbiased, 66ethical challenges, 344, 354–355 Euclidean distance, 75, 202algorithm for, 187as embedded method, 184 continuous variables in, 188 random forests of, 190–192degrees, 257demeaned forecast, 158 demeaned realized, 158 derivativespriors and, 162second, 162 Derman, Emanuel, 354Hippocratic Oath of Modeling,354descriptive models, 194deterministic relationships, 60 diagonal, 208differential calculus, 337digit recognition, 97 dimensionality, 96, 202, 206alternating least squares, 211 optimizing for, 212principal component analysis and,209–211singular value decomposition(SVD) and, 207–209 dimensions, 96directed edges, 137discrete derivative operators, 161 distance metrics (k-NN), 75–77sensitivity of, 203 distant reading, 221 distribution, 20conditional, 32 Gaussian, 30 joint, 32 named, 30 normal, 30distributive crowdsourcing, 167 domain expertise vs. machine learn‐ing algorithms, 175 Dorsey, Jack, 235 Driscoll, Mike, 6 Duhigg, Charles, 269www.finebook.irIndex | 365
evaluating models, 313–320 accuracy and, 315algorithms, choosing, 318 probability vs. binary outcomes,315–318 evaluation metricsA/B testing for, 128for k-NN algorithms, 78for linear regression algorithms,66–70 exercisesBasic Machine Learning Algo‐ rithm, 85–89data visualization, 250financial data, 163for EDA, 37–40GetGlue, 162–164Media 6 Degrees (M6D), 128 Naive Bayes for Article Classifica‐tion, 109–112RealDirect data strategy, 48–49 recommendation engine, building,214simulating datasets, 70 timestamped event data, 162–164experiments, 244explanatory variables, 176explicit assumptions, 53 exploratory data analysis (EDA), 17,29, 34–40code samples for, 38–40exercise for, 37–40financial modeling and, 138–142 modeling and, 29philosophy of, 36–37tools of, 35exponential downweighting, 154, 155 formula for, 155exponential random graph models (ERGMs), 266inference for, 267exponential random graphs, 266FF-score, 127Facebook, 2, 8, 21, 218, 253data science in, 9 366 | IndexKaggle and, 172real-time streaming data, 23 false negative rate, 78false positive rate, 78fault tolerance, 327feature construction, 307 feature extraction, 165, 179 feature generation, 179feature selection, 165, 176–193challenges in, 241criticisms of, 192decision tree algorithm, 187 decision trees, 184entropy, 186filters, 181random forests and, 190–192 user retention example, 177–180 wrapper, 181–183feature selection methods, 180 embedded, 180filters, 180wrappers, 180feature transformation, 307 features, 176feedback loops, 126feedback loops in financial models,156–158filter bubble thought experiment, 213 filters, 180filters, ordering features with, 181 finalizing models, 146financial data exercise, 163financial modelingautocorrelation, correcting, 159– 162financial data exercise, 163 GetGlue exercise, 162–164 logistic regression in, 158priors in, 158timestamped event data exercise,162–164financial models, 145–162causality and, 146–147data preparation for, 147–149 exponential downweighting, 155 feedback loop, 156–158 in-sample data, 146–147log returns and, 149www.finebook.ir
out-of-sample data, 146–147 S&P index example, 151 volatility measurements in, 152–154finite differences, 183Firebug extension, 107Firefox, 107Flickr, 108FOIA requests, 269Foreign Affairs (magazine), 5 forward selection, 182Fourier coefficients, 246fraud, data visualization and, 236–239detecting with machine learning, 236–239performance estimation, 239–242 freeze rates, 248 Fruchterman-Reingold algorithm, 261 functions, 33knn(), 80 likelihood, 122 loss, 68 penalty, 160experimental infrastructures, 281 issues with, 176machine learning and, 52 MapReduce and, 321 mixed-method approaches and,194privacy and, 196sampling and, 21skills for, 8social layer at, 196social research, approach to, 193–198text-mining models and, 13Google glasses, 6 Google+, 41, 193, 195, 253 graph statistics, 266graph theory, 255 grouping data, 81groups, 256Guyon, Isabelle, 180, 181HHadoop, 21, 333–335 analytical applications, 335 Cloudera and, 334core components, 334 MapReduce and, 333Hammerbacher, Jeff, 8, 334 Hamming distance, 76 Hansen, Mark, 217–234 Harris, Harlan, 13Harvard Business Review data science in, 8HDFS, 334heaps, 326Hessian matrix, 123, 124hierarchical modeling, 82high bias, 192high class imbalance, 241Hippocratic Oath of Modeling, 354 Hofman, Jake, 340Howard, Jeremy, 175Hubway Data Visualization challenge,250Huffaker, David, 193human powered airplane thought ex‐periment, 332fundamental problem of causal infer‐ ence, 286Ggarbage in, garbage out scenarios, 165 Gaussian distribution, 30Gaussian mixture model, 56Geller, Nancy, 8Gelman, Andrew, 26general functional form, 31 generating data, 304generative processes, 52 geo-based location data, 23 geographic information systems(GIS), 220geometric mean, 211GetGlue, 135–137, 214GetGlue exercise, 162–164 Giraph, 331GitHub, 335Gmail, 95goodness, 301Google, 2, 3, 4, 5, 21, 53, 126, 193Bell Labs and, 35www.finebook.irIndex | 367
Hunch, 200 hyperparameters, 105IIBM, 309image recognition thought experi‐ment, 108 images, 23incidence lists, 264 incidence matrix, 264 independent trials, 101 individual user plots, 138 inference for ERGMs, 267 inferential degeneracy, 268 information gain, 187maximize, 187 inherent chaos, 45 InnoCentive, 167 inspecting elements, 107 interpretabilityas constraint, 117of logistic regression, 117 predictive power vs., 192machine learning classifications vs., 204–206measurement errors, 203 Naive Bayes vs., 105 recommendation engines and,202–204similarity metrics, 75–77 spam filters and, 96 sparseness, 203test sets, 77training sets, 77Kaggle, 167, 170–173 crowdsourcing and, 167 customer base of, 172 Facebook and, 172 leapfrogging and, 170Katz, Elihu, 255KDD competition, 166 Kelly, John, 254keying datasets, 58 Khan Academy, 5, 207 Knewton, 5knn() function, 80Llabels, 81, 119, 242 churn, 239defining, 241Lander, Jared, 341Laplace smoothing, 103large-scale network analysis thoughtexperiment, 195 latency, 207latent features, 206 most important, 209 latent space models, 268Latour, Bruno, 218 Lazarsfield, Paul, 255 leakage, 307 leapfrogging, 170issues with, 171learning by example thought experi‐ment, 93–97least important vectors, 208 Least Squares, 52 least-squares estimation, 61 lift, 126interpretations, 273 interpreting parameters, 53JJaccard distance, 76, 202 Jensen, Roderick V., 45 join distributions, 32Kk-means algorithm, 55, 56, 81–85 in two dimensions, 82–85 issues with, 84k-Nearest Neighbors (k-NN), 42, 55, 71–81, 115, 125computational complexity, 203 correlated features in, 203cost of, 204credit score example, 73–75 distance metrics, 75–77 importance of features in, 203 issues with, 202k, choosing, 79368 | Indexwww.finebook.ir
likelihood function, 122linear algebra, 207linear regression algorithms, 30, 42,55–71evaluation metrics for, 66–70 models, fitting, 61multiple, 69noise and, 64–66spam filters and, 95using, 55linear regression model, 64 linear relationships, 55, 56 LinkedIn, 8, 253data science in, 9Lives on a Screen (Thorp/Hansen),229log returns vs. percent, 149 logistic regression, 54, 113–128algorithms, understanding, 117 at runtime, 116classifiers, 115–118evaluating, 125–128 implementing, 124in financial modeling, 158 interpretability of, 117 mathematical basis of, 120–122 Media 6 Degrees (M6D) casestudy, 118–128Media 6 Degrees (M6D) exercise,128Newton’s method of, 124output of, 119scalability, 117stochastic gradient descent meth‐od, 124thought experiments for, 113–128logistic regression model, 121 Lorenzian water wheel, 44 loss function, 68lynx, 107lynx --dump, 107Mmachine learning, 52, 235 challenges in, 241data visualization and, 235detecting suspicious activity, with, 236–239Google and, 52models, productionizing, 245 machine learning algorithms, 52, 330domain expertise vs., 175machine learning classifications, 204–206recommendation engines and, 204–206Madigan, David, 291, 344 Mahalanobis distance, 76 Mahout, 124Manhattan distance, 76 MapReduce, 51, 324analytical applications, 335 common usage of, 329 Google and, 321Hadoop and, 333 limitations of, 330using, 322, 328word frequency problems, 328 mathematical models, 27matrix decomposition, 207 maximize information gain, 187 maximum likelihood estimation, 33,123Mayer-Schoenberger, Viktor, 5 McKelvey, Jim, 235MCMC methods, 268mean absolute error, 127mean squared error, 66, 67, 127, 307 meaning of features, 273 measurement errors, 203 Mechanical Turks, 168Amazon, 169crowdsourcing vs., 169 Mechanize, 107Media 6 Degrees (M6D), 343 Media 6 Degrees (M6D) case study,118–128click models for, 118Media 6 Degrees (M6D) exercise, 128 medical data thought experiment,292, 302meta-definition thought experiment,13 Metamarket, 6www.finebook.irIndex | 369
methods, 55feature selection, 180 MCMC, 268metrics, 202Microsoft Research, 21 misclassification rate, 79 mixed-method approaches, 194 modeling, 56EDA and, 29 hierarchical, 82 skills for, 307 statistical, 52 time series, 143modeling assumptionsBig Data and, 24–26in k-NN algorithms, 80models, 26–34, 244adding assumptions about errors,64–66algorithms vs., 56, 56at scale, 89autocorrelation, correcting, 159–162building, 29, 243–247causal, 146causality and, 146–147coding for, 243–245data, 26defined, 27 descriptive/predictive, 194 designing, 333developing, 135–164EDA and, 138–142evaluating, 313–320exploratory data analysis (EDA),34–40exponential downweighting, 155 feature selection for, 176–193 finalizing, 146financial, 145–162fitting, 33, 61GetGlue and, 135–137 in-sample data, 146–147latent space, 268linear regression, 64logistic regression, 121 mathematical, 27out-of-sample data, 146–147overfitting, 34probabilistic, 94probability distributions and, 30–33productionizing, 245 relying on data leakage, 308 statistical, 26, 28, 30 timestamps and, 137 timestamps in training datathought experiment, 144 volatility measurements in, 152–154MONK project, 234Moretti, Franco, 221Morningside Analytics, 253, 260–263 most important latent features, 209 Moveable Type (Rubin/Hansen), 226–229multiple linear regression, 69NNaive Bayes, 30, 42, 54, 96, 98–102, 115, 125algorithm, 102Bayes law, 98combining words in, 101 k-NN vs., 105training classifiers, 339 using, 99Naive Bayes for Article Classification exercise, 109–112, 339named distribution, 30natural language processing (NLP),112, 260negative log likelihood, 123 neighbors, 72Netflix, 25recommendation engines and, 199 network data, 23networkssmall-world, 268undirected, 264New Scientist (magazine), 175 New York Times API, 110 Newton’s method of logistic regres‐sion, 52, 124370 | Indexwww.finebook.ir
nodes, 136, 256 pairs of, 258noise, 65noise in linear regression models, 64–66normal distribution, 30 normalized Gini coefficient, 172 normalizing data, 148null hypothesis, 67, 183OObservational Medical Outcomes Partnership, 298–302observational studies, 278, 283–289 causal effect, 287causality, visualizing, 286–287 improving on, 296–298in medical literature, 293 Rubin Causal Model, 285 Simpson’s Paradox, 283–285observations, 20observed errors, 66observed features, 81OK Cupid, 276–279 orthogonal, 207, 208 overfitting models, 34, 203, 205 oversampling, 309O’Neil, Cathy, 143Pp-values, 67, 183Pandora, 137parallelizing, 332 parameter estimation, 52 parameters, interpreting, 53 parsing tools, 107Beautiful Soup, 107 lynx, 107lynx --dump, 107 Mechanize, 107 PostScript, 107Patil, DJ, 8patterns, 36penalty function, 160 percent returns, 149log vs., 149 scaled, 149performance estimation, 239–242 Perlich, Claudia, 303–305, 343 Perlson, Doug, 46personal data collection thought ex‐periment, 219 Pinterest, 47polishing, 339 populations, 19distinctions between samples and,19 super-, 22position, 126position normalize, 126 PostScript, 107precision, 78, 127, 240predicted preference, 210 predicting attributes, 204 predictions, 54, 57, 177, 273, 355 predictive models, 194 predictive power, 53interpretability vs., 192 predictors, 176adding, 69Pregel, 51, 331 prescriptionists, 13Principal Component Analysis(PCA), 206, 209–211 priors, 212higher derivatives and, 162in financial modeling, 158 privacy thought experiment, 197 privacy, data science and, 196 probabilistic models, 94 probability, 30, 119, 315binary outcomes vs., 315–318 probability distributions, 30–33 problems with channels, 325 process thinking, 337–339 processesdata-generating, 19 generative, 52 real-world, 19Processing programming language,221 products, 5proximity clustering, 261 prtobuf, 335www.finebook.irIndex | 371
pseudo-likelihood estimation proce‐ dure, 268pseudocounts, 105 purity, 318QQuora, 6RR-squared, 67, 182 random forests, 190–192 random graphs, 265–267Erdos-Renyi model, 265–267exponential, 266random variables, 32ranks, 126, 207real-life performance measures, 307 real-time streaming data, 23 real-world data, 339real-world processes, 19 RealDirect, 46website, 48RealDirect case study, 46–49 RealDirect data strategy exercise, 48–49realizations, 33recall, 78, 127, 240receiver operating characteristiccurve, 125recommendation engines, 199–214Amazon and, 199building, exercise, 214 dimensionality, 206k-Nearest Neighbors (k-NN) and,relationships deterministic, 60 understanding, 57relative time differentials, 144 residual sum of squares (RSS), 62 residuals, 66retention, understanding, 177 return, 188Robo-Graders, ethical implications of as thought experiment, 174ROC curve, 125root squared error, 127Rube Goldberg machines, 333 Rubin Causal Model, 285 RunMyCode, 355running estimates, 149SS&P index example, 151 samples vs. populations, 19 sampling, 21, 22distribution, 22 issues with, 309 problems, 309 users, 309sampling distribution, 22 scaled percent returns, 149 scientific method, 44 scikit-earn, 244second derivatives, 162 segmentation, 81semi-supervised learning problems,239 sensitivity, 78sensor data, 23Shakespeare Machine (Rubin/Hansen), 233sharding datasets, 89shards, 329shift operators, 161signals, 244similarity metrics (k-NN), 72, 75–77 Simpson’s Paradox, 283–285Singular Value Decomposition (SVD),206singular value decomposition (SVD), 207–209202–204machine learning classificationsand, 204–206 Netflix and, 199 real-world, 200records, 23Red Hat, 334Reddy, Ben, 341 redundancies, 176 regression, stepwise, 181 regular expressions, 341 relational ties, 256 relations, 256372 | Indexwww.finebook.ir
small-world networks, 268 social annotation, 196social network analysis, 255, 260 social networks, 254–269analysis of, 255as school of fish, 262case attribute data vs., 254 centrality measures, 257–259 eigenvalue centrality and, 264 Morningside Analytics, 260–263 representations of, 264 terminology of, 256social research, 165–198extracting meaning from, 165–198 feature selection, 176–193sociometry, 255 spam classifiers, 119 spam filters, 93–112stepwise regression, 181 combined approach to, 182 methods of, 181stochastic gradient descent, 52, 124 stratifications, 289, 294stratifying data, 81subgroups, 256subnetworks, 256 super-populations, 22 supervised learning, 81k-Nearest Neighbor algorithms, 71–81linear regression algorithms, 55– 71supervised learning recipe, 239 Suriowiecki, James, 169 Survival Analysis, 177Ttacit knowledge, 357 Tarde, Gabriel, 218, 343Idea of Quantification, 218Taylor Series, 183teaching data science thought experi‐ment, 348 test sets, 77tests, 244text data, 23 text-mining models, 13 TF-IDF vectors, 340 thought experimentsaccess to medical records, 323 automated statistician, 91chaos simulation, 44data science as a science, 114–128 Egyptian politics, 259filter bubble, 213human powered airplane, 332 image recognition, 108 large-scale network analysis, 195 learning by example, 93–97 medical data, 292, 302 meta-definitions, 13personal data collection, 219 privacy, concerns/understandingof, 197combining words in, 101for individual words, 99–101 k-Nearest Neighbors (k-NN) and,96Laplace smoothing, 103 learning by example thought ex‐periment, 93–97linear regression algorithms and,95Naive Bayes, 98–102span, 207sparse vectors, 202sparseness, 203specific conditional entropy, 187 specificity, 78Square, 235challenges of, 236data visualization at, 247–248 Square Wallet, 235statistical inference, 18, 19, 66 statistical models, 26, 30, 52 statistics, 7, 8, 17–34epidemiology and, 293 graph, 266journals, 293 modeling, 26–34 populations, 19 samples, 19statistical inference, 18www.finebook.irIndex | 373
Robo-Graders, ethical implications of, 174teaching data science, 348 timestamps in training data, 144 transaction data, 248unified theory of data science,114–128 thresholds, 300Thrift, 335time series modeling, 143 timestamped event data exercise, 162–164timestamps absolute, 144financial modeling and, 137issues with, 142timestamps in training data thoughtexperiment, 144tolerance, 327traditional data, 23traditional data fields, 220training sets, 77transaction data thought experiments,sensor, 23 text, 23 traditional, 23Ullman, Ellen, 40unbiased estimators, 66 undirected networks, 264 unexplained variance, 67unit level causal effect, 285unit subsets, 20unsupervised learning, 84 untreated, 275usagists, 13user retention example, 177–180interpretability vs.predictive pow‐ er, 192using MapReduce, 328Vvariables correlated, 176 random, 32variance, 67 variation, 60, 64 vectorsleast important, 208TF-IDF, 340Venn diagram of data science, 7 visualization, 8visualization radiators, 247 volatility estimates, 152volatility measurements, 152–154 Vowpal Wabbit, 124Wweb, scraping data from, 106–108 Wikipedia, 167Wills, Josh, 53, 331Wong, Ian, 234–248word frequency problems, 325–329 wrapper feature selection, 181–183algorithms, selecting, 181criterion for, 182 wrappers, 180248transformations, 69 transforming data, 148 transforming features, 307 transitivity, 266 translations, 271 transpose, 207treated, 275trees, 318trends, 60, 64triadic closures, 256 triads, 256true negative rate, 78true positive rate, 78true regression line, 65 Tukey, John, 34Twitter, 21, 253, 259Lives on a Screen (Thorp/Hansen),229 types of data, 23geo-based location, 23 images, 23network, 23real-time streaming, 23 records, 23U374 | Indexwww.finebook.ir
Xxml descriptions, 234YYahoo!Developer Network, 107YQL Language, 107 Yau, Nathan, 7, 250ZZillow, 47www.finebook.irIndex | 375
About the AuthorsRachel Schutt is the Senior Vice President of Data Science at News Corp. She earned a PhD in Statistics from Columbia University, and was a statistician at Google Research for several years. She is an adjunct professor in Columbia’s Department of Statistics and a founding member of the Education Committee for the Institute for Data Sci‐ ences and Engineering at Columbia. She holds several pending patents based on her work at Google, where she helped build user-facing products by prototyping algorithms and building models to under‐ stand user behavior. She has a master’s degree in mathematics from NYU, and a master’s degree in Engineering-Economic Systems and Operations Research from Stanford University. Her undergraduate degree is in Honors Mathematics from the University of Michigan.Cathy O’Neil earned a PhD in math from Harvard, was a postdoc at the MIT math department, and a professor at Barnard College, where she published a number of research papers in arithmetic algebraic ge‐ ometry. She then chucked it and switched over to the private sector. She worked as a quant for the hedge fund D.E. Shaw in the middle of the credit crisis, and then for RiskMetrics, a risk software company that assesses risk for the holdings of hedge funds and banks. She is currently a data scientist on the New York startup scene, writes a blog at mathbabe.org, and is involved with Occupy Wall Street.ColophonThe animal on the cover of Doing Data Science is a nine-banded armadillo (Dasypus novemcinctus), a mammal widespread through‐ out North, Central, and South America. From Latin, novemcinctus literally translates to “nine-banded” (after the telescoping rings of ar‐ mor around the midsection), though the animal can actually have be‐ tween 7 to 11 bands. The three-banded armadillo native to South America is the only armadillo that can roll into a ball for protection; other species have too many plates.The armadillo’s skin is perhaps its most notable feature. Brownish-gray and leathery, it is composed of scaly plates called scutes that cover everything but its underside. The animals also have powerful digging claws, and are known to create several burrows within their territory, which they mark with scent glands. Nine-banded armadillos typically weigh between 5.5 to 14 pounds, and are around the size of a largewww.finebook.ir
domestic cat. Its diet is largely made up of insects, though it will also eat fruit, small reptiles, and eggs.Females almost always have a litter of four—quadruplets of the same gender, because the zygote splits into four embryos after implantation. Young armadillos have soft skin when they are born, but it hardens as they get older. They are able to walk within a few hours of birth.Nine-banded armadillos are capable of jumping three to four feet in the air if startled. Though this reaction can scare off natural predators, it is usually fatal for the armadillo if an approaching car is what has frightened it, as it will collide with the underside of the vehicle. An‐ other unfortunate connection between humans and nine-banded ar‐ madillos is that they are the only carriers of leprosy—it is not unheard of for humans to become infected when they eat or handle armadillos.The cover image is from Shaw’s Zoology, and was reinterpreted in color by Karen Montgomery. The cover fonts are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu Mono.www.finebook.ir