
CHAPTER 10 Social Networks and Data JournalismIn this chapter we’ll explore two topics that have started to become especially hot over the past 5 to 10 years: social networks and data journalism. Social networks (not necessarily just online ones) have been studied by sociology departments for decades, as has their coun‐ terpart in computer science, math, and statistics departments: graph theory. However, with the emergence of online social networks such as Facebook, LinkedIn, Twitter, and Google+, we now have a new rich source of data, which opens many research problems both from a so‐ cial science and quantitative/technical point of view.We’ll hear first about how one company, Morningside Analytics, vis‐ ualizes and finds meaning in social network data, as well as some of the underlying theory of social networks. From there, we look at con‐ structing stories that can be told from social network data, which is a form of data journalism. Thinking of the data scientist profiles—and in this case, gene expression is an appropriate analogy—the mix of math, stats, communication, visualization, and programming re‐ quired to do either data science or data journalism is slightly different, but the fundamental skills are the same. At the heart of both is the ability to ask good questions, to answer them with data, and to com‐ municate one’s findings. To that end, we’ll hear briefly about data journalism from the perspective of Jon Bruner, an editor at O’Reilly.www.finebook.ir253
Social Network Analysis at Morning AnalyticsThe first contributor for this chapter is John Kelly from Morningside Analytics, who came to talk to us about network analysis.Kelly has four diplomas from Columbia, starting with a BA in 1990 from Columbia College, followed by a master’s, MPhil, and PhD in Columbia’s School of Journalism, where he focused on network soci‐ ology and statistics in political science. He also spent a couple of terms at Stanford learning survey design and game theory and other quanty stuff. He did his master’s thesis work with Marc Smith from Micro‐ soft; the topic was how political discussions evolve as networks. After college and before grad school, Kelly was an artist, using computers to do sound design. He spent three years as the director of digital media atColumbia School of the Arts. He’s also a programmer: Kelly taught himself Perl and Python when he spent a year in Vietnam with his wife.Kelly sees math, statistics, and computer science (including machine learning) as tools he needs to use and be good at in order to do what he really wants to do. Like a chef in a kitchen, he needs good pots and pans and sharp knives, but the meal is the real product.And what is he serving up in his kitchen? Kelly wants to understand how people come together, and when they do, what their impact is on politics and public policy. His company, Morningside Analytics, has clients like think tanks and political organizations. They typically want to know how social media affects and creates politics.Communication and presentations are how he makes money—visu‐ alizations are integral to both domain expertise and communications —so his expertise lies in visualization combined with drawing con‐ clusions from those visualizations. After all, Morningside Analytics doesn’t get paid to just discover interesting stuff, but rather to help people use it.Case-Attribute Data versus Social Network DataKelly doesn’t model data in the standard way through case-attribute data. Case-attribute refers to how you normally see people feed models with various “cases,” which can refer to people or events—each of which have various “attributes,” which can refer to age, or operating system, or search histories.254 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
Modeling with case-attribute data started in the 1930s with early mar‐ ket research, and it was soon being applied to marketing as well as politics.Kelly points out that there’s been a huge bias toward modeling with case-attribute data. One explanation for this bias is that it’s easy to store case-attribute data in databases, or because it’s easy to collect this kind of data. In any case, Kelly thinks it’s missing the point of the many of the questions we are trying to answer.He mentioned Paul Lazarsfeld and Elihu Katz, two trailblazing soci‐ ologists who came here from Europe and developed the field of social network analysis, an approach based not only on individual people but also the relationships between them.To get an idea of why network analysis is sometimes superior to case- attribute data analysis, think about the following example. The federal government spent money to poll people in Afghanistan. The idea was to see what citizens want in order to anticipate what’s going to happen in the future. But, as Kelly points out, what’ll happen isn’t a simple function of what individuals think; instead, it’s a question of who has the power and what they think.Similarly, imagine going back in time and conducting a scientific poll of the citizenry of Europe in 1750 to determine the future politics. If you knew what you were doing you’d be looking at who was marrying whom among the royalty.In some sense, the current focus on case-attribute data is a problem of looking for something “under the streetlamp”—a kind of observatio‐ nal bias wherein people are used to doing things a certain (often easier) way so they keep doing it that way, even when it doesn’t answer the questions they care about.Kelly claims that the world is a network much more than it’s a bunch of cases with attributes. If you only understand how individuals be‐ have, how do you tie things together?Social Network AnalysisSocial network analysis comes from two places: graph theory, where Euler solved the Seven Bridges of Konigsberg problem, and sociome‐ try, started by Jacob Moreno in the 1970s, a time when early computerswww.finebook.irSocial Network Analysis | 255
were getting good at making large-scale computations on large datasets.Social network analysis was germinated by Harrison White, professor emeritus at Columbia, contemporaneously with Columbia sociologist Robert Merton. Their idea was that people’s actions have to be related to their attributes, but to really understand them you also need to look at the networks (aka systems) that enable them to do something.How do we bring that idea to our models? Kelly wants us to consider what he calls the micro versus macro, or individual versus systemic divide: how do we bridge this divide? Or rather, how does this divide get bridged in various contexts?In the US, for example, we have formal mechanisms for bridging those micro/macro divides, namely markets in the case of the “buying stuff ” divide, and elections in the case of political divides. But much of the world doesn’t have those formal mechanisms, although they often have a fictive shadow of those things. For the most part, we need to know enough about the actual social network to know who has the power and influence to bring about change.Terminology from Social NetworksThe basic units of a network are called actors or nodes. They can be people, or websites, or whatever “things” you are considering, and are often indicated as a single dot in a visualization. The relationships between the actors are referred to as relational ties or edges. For ex‐ ample, an instance of liking someone or being friends would be indi‐ cated by an edge. We refer to pairs of actors as dyads, and triplets of actors as triads. For example, if we have an edge between node A and node B, and an edge between node B and node C, then triadic closure would be the existence of an edge between node A and node C.We sometimes consider subgroups, also called subnetworks, which consist of a subset of the whole set of actors, along with their relational ties. Of course this means we also consider the group itself, which means the entirety of a “network.” Note that this is a relatively easy concept in the case of, say, the Twitter network, but it’s very hard in the case of “liberals.”We refer to a relation generally as a way of having relational ties be‐ tween actors. For example, liking another person is a relation, but so256 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
is living with someone. A social network is the collection of some set of actors and relations.There are actually a few different types of social networks. For exam‐ ple, the simplest case is that you have a bunch of actors connected by ties. This is a construct you’d use to display a Facebook graph—any two people are either friends or aren’t, and any two people can theo‐ retically be friends.In bipartite graphs the connections only exist between two formally separate classes of objects. So you might have people on the one hand and companies on the other, and you might connect a person to a company if she is on the board of that company. Or you could have people and the things they’re possibly interested in, and connect them if they really are.Finally, there are ego networks, which is typically formed as “the part of the network surrounding a single person.” For example, it could be “the subnetwork of my friends on Facebook,” who may also know one another in certain cases. Studies have shown that people with higher socioeconomic status have more complicated ego networks, and you can infer someone’s level of social status by looking at their ego network.Centrality MeasuresThe first question people often ask when given a social network is:who’s important here?Of course, there are different ways to be important, and the different definitions that attempt to capture something like importance lead to various centrality measures. We introduce here some of the commonly used examples.First, there’s the notion of degree. This counts how many people are connected to you. So in Facebook parlance, this is the number of friends you have.Next, we have the concept of closeness: in words, if you are “close” to everyone, you should have a high closeness score.To be more precise, we need the notion of distance between nodes in a connected graph, which in the case of a friend network means everyone is connected with everyone else through some chain of mu‐ tual friends. The distance between nodes x and y, denoted by d x, y ,Terminology from Social Networks | 257www.finebook.ir
is simply defined as the length of the shortest path between the two nodes. Now that you have this notation, you can define the closeness of node x as the sum:Cx =∑2−dx,ywhere the sum is over all nodes y distinct from x.Next, there’s the centrality measure called betweenness, which meas‐ ures the extent to which people in your network know each other through you, or more precisely whether the shortest paths between them go through you. The idea here is that if you have a high betwe‐ enness score, then information probably flows through you.To make this precise, for any two nodes x and y in the same connected part of a network, define σ x, y to be the number of shortest paths between node x and node y, and define σx,y  v  to be the number of shortest paths between node x and node y that go through a third node v. Then the betweenness score of v is defined as the sum:Bv =∑σx,y v σx,ywhere the sum is over all distinct pairs of nodes x and y that are distinct from v.The final centrality measure, which we will go into in detail in “Rep‐ resentations of Networks and Eigenvalue Centrality” on page 264 after we introduce the concept of an incidence matrix, is called eigenvector centrality. In words, a person who is popular with the popular kids has high eigenvector centrality. Google’s PageRank is an example of such a centrality measure.The Industry of Centrality MeasuresIt’s important to issue a caveat on blindly applying the preceding cen‐ trality measures. Namely, the “measurement people” form an industry in which everyone tries to sell themselves as the authority. But expe‐ rience tells us that each has their weaknesses and strengths. The main thing is to know you’re looking at the right network or subnetwork.For example, if you’re looking for a highly influential blogger in the Muslim Brotherhood, and you write down the top 100 bloggers in258 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
some large graph of bloggers, and start on the top of the list, and go down the list looking for a Muslim Brotherhood blogger, it won’t work: you’ll find someone who is both influential in the large network and who blogs for the Muslim Brotherhood, but they won’t be influential with the Muslim Brotherhood, but rather with transnational elites in the larger network. In other words, you have to keep in mind the local neighborhood of the graph.Another problem with centrality measures: experience dictates that different contexts require different tools. Something might work with blogs, but when you work with Twitter data, you’ll need to get out something entirely different.One reason is the different data, but another is the different ways peo‐ ple game centrality measures. For example, with Twitter, people create 5,000 Twitter bots that all follow one another and some strategically selected other (real) people to make them look influential by some measure (probably eigenvector centrality). But of course this isn’t ac‐ curate; it’s just someone gaming the measures.Some network packages exist already and can compute the various centrality measures mentioned previously. For example, see NetworkX or igraph if you use Python, or statnet for R, or NodeXL, if you prefer Excel, and finally keep an eye out for a forthcoming C package from Jure Leskovec at Stanford.Thought ExperimentYou’re part of an elite, well-funded think tank in DC. You can hire people and you have $10 million to spend. Your job is to empirically predict the future political situation of Egypt. What kinds of political parties will there be? What is the country of Egypt going to look like in 5, 10, or 20 years? You have access to exactly two of the following datasets for all Egyptians: the Facebook or Twitter network, a complete record of who went to school with who, the text or phone records of everyone, everyone’s addresses, or the network data on members of all formal political organizations and private companies.Before you decide, keep in mind that things change over time—people might migrate off of Facebook, or political discussions might need to go underground if blogging is too public. Also, Facebook alone gives a lot of information, but sometimes people will try to be stealthy—www.finebook.irThought Experiment | 259
maybe the very people you are most interested in keeping tabs on. Phone records might be a better representation for that reason.If you think this scenario is ambitious, you should know it’s already being done. For example, Siemens from Germany sold Iran software to monitor their national mobile networks. In fact, governments are, generally speaking, putting more energy into loading the field with their allies, and less with shutting down the field: Pakistan hires Amer‐ icans to do their pro-Pakistan blogging, and Russians help Syrians.One last point: you should consider changing the standard direction of your thinking. A lot of the time people ask, what can we learn from this or that data source? Instead, think about it the other way around: what would it mean to predict politics in a society? And what kind of data do you need to know to do that?In other words, figure out the questions first, and then look for the data to help answer them.Morningside AnalyticsKelly showed us a network map of 14 of the world’s largest blogo‐ spheres. To understand the pictures, you imagine there’s a force, like a wind, which sends the nodes (blogs) out to the edge, but then there’s a counteracting force, namely the links between blogs, which attach them together. Figure 10-1 shows an example of the Arabic blogo‐ sphere.The different colors represent countries and clusters of blogs. The size of each dot is centrality through degree, i.e., the number of links to other blogs in the network. The physical structure of the blogosphere can give us insight.If we analyze text using natural language processing (NLP), thinking of the blog posts as a pile of text or a river of text, then we see the micro or macro picture only—we lose the most important story. What’s missing there is social network analysis (SNA), which helps us map and analyze the patterns of interaction. The 12 different international blogospheres, for example, look different. We can infer that different societies have different interests, which give rise to different patterns.But why are they different? After all, they’re representations of some higher dimensional thing projected onto two dimensions. Couldn’t it be just that they’re drawn differently? Yes, but we can do lots of text260 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
Figure 10-1. Example of the Arabic blogosphereanalysis that convinces us these pictures really are showing us some‐ thing. We put an effort into interpreting the content qualitatively.So, for example, in the French blogosphere, we see a cluster that dis‐ cusses gourmet cooking. In Germany we see various clusters discus‐ sing politics and lots of crazy hobbies. In English blogs we see two big clusters [Cathy/mathbabe interjects: gay porn and straight porn?]. They turn out to be conservative versus liberal blogs.In Russia, their blogging networks tend to force people to stay within the networks, which is why we see very well-defined, partitioned clusters.The proximity clustering is done using the Fruchterman-Reingold al‐ gorithm, where being in the same neighborhood means your neigh‐ bors are connected to other neighbors, so really it reflects a collectivewww.finebook.irMorningside Analytics | 261
phenomenon of influence. Then we interpret the segments. Figure 10-2 shows an example of English language blogs.Figure 10-2. English language blogsHow Visualizations Help Us Find Schools of FishSocial media companies are each built around the fact that they either have the data or they have a toolkit—a patented sentiment engine or something, a machine that goes ping. Keep in mind, though, that social media is heavily a product of organizations that pay to move the needle —that is, that game the machine that goes ping. To believe what you see, you need to keep ahead of the game, which means you need to decipher that game to see how it works. That means you need to visualize.Example: if you are thinking about elections, look at people’s blogs within “moms” or “sports fans.” This is more informative than looking at partisan blogs where you already know the answer.Here’s another example: Kelly walked us through an analysis, after binning the blogosphere into its segments, of various types of links to262 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
partisan videos like MLK’s “I Have a Dream” speech, and a video from the Romney campaign. In the case of the MLK speech, you see that it gets posted in spurts around the election cycle events all over the blo‐ gosphere, but in the case of the Romney campaign video, you see a concerted effort by conservative bloggers to post the video in unison.That is to say, if you were just looking at a histogram of links—a pure count—it might look as if the Romney video had gone viral, but if you look at it through the lens of the understood segmentation of the blo‐ gosphere, it’s clearly a planned operation to game the “virality” measures.Kelly also works with the Berkman Center for Internet and Society at Harvard. He analyzed the Iranian blogosphere in 2008 and again in 2011, and he found much the same in terms of clustering—young anti- government democrats, poetry (an important part of Iranian culture), and conservative pro-regime clusters dominated in both years.However, only 15% of the blogs are the same from 2008 to 2011.So, whereas people are often concerned about individuals (the case- attribute model), the individual fish are less important than the schools of fish. By doing social network analysis, we are looking for the schools, because that way we learn about the salient interests of the society and how those interests are stable over time.The moral of this story is that we need to focus on meso-level patterns, not micro- or macro-level patterns.More Background on Social Network Analysis from a Statistical Point of ViewOne way to start with SNA is to think about a network itself as a ran‐ dom object, much like a random number or random variable. The network can be conceived of as the result of a random process or as coming from an underlying probability distribution. You can in fact imagine a sample of networks, in which case you can ask questions like: What characterizes networks that might conceivably be Twitter- like? Could a given network reflect real-world friendships? What would it even mean to say yes or no to this question?These are some of the basic questions in the discipline of social net‐ work analysis, which has emerged from academic fields such as math, statistics, computer science, physics, and sociology, with far-rangingMore Background on Social Network Analysis from a Statistical Point of View | 263www.finebook.ir
applications in even more fields including fMRI research, epidemiol‐ ogy, and studies of online social networks such as Facebook or Google+.Representations of Networks and Eigenvalue CentralityIn some networks, the edges between nodes are directed: I can follow you on Twitter when you don’t follow me, so there will be an edge from me to you. But other networks have only symmetric edges: we either know each other or don’t. These latter types of networks are called undirected.An undirected network with N nodes can be represented by an N × N matrix comprised of 1s and 0s, where the (i, j)th element in the matrix is a 1 if and only if nodes i and j are connected. This matrix is known as an adjacency matrix, or incidence matrix. Note that we can actually define this for directed networks too, but for undirected networks, the matrix is always symmetric.Alternatively, a network can be represented by a list of lists: for each node i, we list the nodes to which node i is connected. This is known as an incidence list, and note that it doesn’t depend on the network being undirected. Representing the network this way saves storage space—the nodes can have attributes represented as a vector or list. For example, if the nodes are people, the attributes could be demo‐ graphic information or information about their behavior, habits, or tastes.The edges themselves can also have values, or weights/vectors, which could capture information about the nature of the relationship be‐ tween the nodes they connect. These values could be stored in the N × N matrix, in place of the 1s and 0s that simply represent the pres‐ ence or not of a relationship.Now with the idea of an adjacency matrix A in mind, we can finally define eigenvalue centrality, which we first mentioned in “Centrality Measures” on page 257. It is compactly defined as the unique vector solution x to the equation:Ax=λx such that264 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
xi>0, i=1⋯NAs it turns out, that last condition is equivalent to choosing the largest eigenvalue λ. So for an actual algorithm, find the roots of the equation det  A − tI  and order them by size, grabbing the biggest one and calling it λ. Then solve for x by solving the system of equations:A−λI x=0Now we have x, the vector of eigenvector centrality scores.Note this doesn’t give us much of a feel for eigenvalue centrality, even if it gives us a way to compute it. You can get that feel by thinking about it as the limit of a simple iterative scheme—although it requires proof, which you can find, for example, here.Namely, start with a vector whose entries are just the degrees of the nodes, perhaps scaled so that the sum of the entries is 1. The degrees themselves aren’t giving us a real understanding of how interconnec‐ ted a given node is, though, so in the next iteration, add the degrees of all the neighbors of a given node, again scaled. Keep iterating on this, adding degrees of neighbors one further step out each time. In the limit as this iterative process goes on forever, we’ll get the eigen‐ value centrality vector.A First Example of Random Graphs: The Erdos-Renyi ModelLet’s work out a simple example where a network can be viewed as a single realization of an underlying stochastic process. Namely, where the existence of a given edge follows a probability distribution, and all the edges are considered independently.More Background on Social Network Analysis from a Statistical Point of View | 265www.finebook.ir
Say we start with N nodes. Then there are D =  N2  pairs of nodes, or dyads, which can either be connected by an (undirected) edge or not.Then there are 2D possible observed networks. The simplest under‐ lying distribution one can place on the individual edges is called the Erdos-Renyi model, which assumes that for every pair of nodes i, j , an edge exists between the two nodes with probability p.The Bernoulli NetworkNot all networks with N nodes occur with equal probability under this model: observing a network with all nodes attached to all othernodes has probability pD, while observing a network with all nodesdisconnected has probability  1 − p D . And of course there are many other possible networks between these two extremes. The Erdos- Renyi model is also known as a Bernoulli network. In the mathematics literature, the Erdos-Renyi model is treated as a mathematical object with interesting properties that allow for theorems to be proved.A Second Example of Random Graphs: The Exponential Random Graph ModelHere’s the bad news: social networks that can be observed in the real world tend not to resemble Bernoulli networks. For example, friend‐ ship networks or academic collaboration networks commonly exhibit characteristics such as transitivity (the tendency, when A knows B and B knows C, that A knows C), clustering (the tendency for more or less well-defined smallish groups to exist with larger networks), reci‐ procity or mutuality (in a directed network, the tendency for A to follow B if B follows A), and betweenness (the tendency for there to exist special people through whom information flows).Some of these observed properties of real-world networks are pretty simple to translate into mathematical language. For example, transi‐ tivity can be captured by the number of triangles in a network.Exponential random graph models (ERGMs) are an approach to cap‐ ture these real-world properties of networks, and they are commonly used within sociology.The general approach for ERGMs is to choose pertinent graph statistics like the number of triangles, the number of edges, and the number of266 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
2-stars (subgraphs consisting of a node with two spokes—so a node with degree 3 has three 2-stars associated to it) given the number of nodes, and have these act as variables zi of your model, and then tweak the associated coefficients θi to get them tuned to a certain type of behavior you observe or wish to simulate. If z1 refers to the number of triangles, then a positive value for θ1 would indicate a tendency toward a larger number of triangles, for example.Additional graph statistics that have been introduced include k-stars (subgraphs consisting of a node with k spokes—so a node with degree k+1 has k+1 k-stars associated with it), degree, or alternating k- stars, an aggregation statistics on the number of k-stars for various k. Let’s give you an idea of what an ERGM might look like formula-wise:PrY=y=κ1 θ1z1y+θ2z2y+θ3z3yHere we’re saying that the probability of observing one particular re‐ alization of a random graph or network, Y, is a function of the graph statistics or properties, which we just described as denoted by zi.In this framework, a Bernoulli network is a special case of an ERGM, where we only have one variable corresponding to number of edges.Inference for ERGMsIdeally—though in some cases unrealistic in practice—one could ob‐ serve a sample of several networks, Y1,...,Yn, each represented by their adjacency matrices, say for a fixed number N of nodes.Given those networks, we could model them as independent and identically distributed observations from the same probability model. We could then make inferences about the parameters of that model.As a first example, if we fix a Bernoulli network, which is specified by the probability p of the existence of any given edge, we can calculate the likelihood of any of our sample networks having come from that Bernoulli network asL = ∏ ni p d i 1 − p D − d iwhere di is the number of observed edges in the ith network and D is the total number of dyads in the network, as earlier. Then we can back out an estimator for p as follows:More Background on Social Network Analysis from a Statistical Point of View | 267www.finebook.ir
∑n di p= i=1nDIn practice in the ERGM literature, only one network is observed, which is to say we work with a sample size of one. From this one example we estimate a parameter for the probability model that “generated” this network. For a Bernoulli network, from even just one network, we could estimate p as the proportion of edges out of the total number of dyads, which seems a reasonable estimate.But for more complicated ERGMs, estimating the parameters from one observation of the network is tough. If it’s done using something called a pseudo-likelihood estimation procedure, it sometimes pro‐ duces infinite values (see Mark Handcock’s 2003 paper, “Assessing Degeneracy of Statistical Models of Social Networks”). If it’s instead done using something called MCMC methods, it suffers from some‐ thing called inferential degeneracy, where the algorithms converge to degenerate graphs—graphs that are complete or empty—or the algo‐ rithm does not converge consistently (also covered in Handcock’s paper).Further examples of random graphs: latent space models, small-world networksMotivated by problems of model degeneracy and instability in expo‐ nential random graph models, researchers introduced latent space models (see Peter Hoff ’s “Latent Space Approaches to Social Network Analysis”).Latent space models attempt to address the following issue: we observe some reality, but there is some corresponding latent reality that we cannot observe. So, for example, we may observe connections between people on Facebook, but we don’t observe where those people live, or other attributes that make them have a tendency to befriend each other.Other researchers have proposed small-world networks (see the Watts and Strogatz model proposed in their 1998 paper), which lie on a spectrum between completely random and completely regular graphs and attempt to capture the real-world phenomenon of six degrees of separation. A criticism of this model is that it produces networks that are homogeneous in degree, whereas observable real-world networks tend to be scale-free and inhomogeneous in degree.268 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
In addition to the models just described, other classes of models in‐ clude Markov random fields, stochastic block models, mixed mem‐ bership models, and stochastic block mixed membership models— each of which model relational data in various ways, and seek to include properties that other models do not. (See, for example, the paper “Mixed Membership Stochastic Block Models” by Edoardo Air‐ oli, et al.)Here are some textbooks for further reading:• Networks, Crowds, and Markets (Cambridge University Press) by David Easley and Jon Kleinberg at Cornell’s computer science de‐ partment.• Chapter on Mining Social-Network graphs in the book Mining Massive Datasets (Cambridge University Press) by Anand Ra‐ jaraman, Jeff Ullman, and Jure Leskovec in Stanford’s computer science department.• Statistical Analysis of Network Data (Springer) by Eric D. Kolaz‐ cyk at Boston University.Data JournalismOur second speaker of the night was Jon Bruner, an editor at O’Reilly who previously worked as the data editor at Forbes. He is broad in his skills: he does research and writing on anything that involves data.A Bit of History on Data JournalismData journalism has been around for a while, but until recently, computer-assisted reporting was a domain of Excel power users. (Even now, if you know how to write an Excel program, you’re an elite.)Things started to change recently: more data became available to us in the form of APIs, new tools, and less expensive computing power —so almost anyone can analyze pretty large datasets on a laptop. Pro‐ gramming skills are now widely enough held so that you can find people who are both good writers and good programmers. Many peo‐ ple who are English majors know enough about computers to get by; or on the flip side, you’ll find computer science majors who can write.In big publications like the New York Times, the practice of data jour‐ nalism is divided into fields: graphics versus interactive features,www.finebook.irData Journalism | 269
research, database engineers, crawlers, software developers, and domain-expert writers. Some people are in charge of raising the right questions but hand off to others to do the analysis. Charles Duhigg at the New York Times, for example, studied water quality in New York, and got a Freedom of Information Act request to the State of New York —he knew enough to know what would be in that FOIA request and what questions to ask, but someone else did the actual analysis.At a smaller organization, things are totally different. Whereas the New York Times has 1,000 people on its newsroom “floor,” The Econ‐ omist has maybe 130, and Forbes has 70 or 80 people in its newsrooms. If you work for anything besides a national daily, you end up doing everything by yourself: you come up with a question, you go get the data, you do the analysis, then you write it up. (Of course, you can also help and collaborate with your colleagues when possible.)Writing Technical Journalism: Advice from an ExpertJon was a math major in college at the University of Chicago, after which he took a job writing at Forbes, where he slowly merged back into quantitative work. For example, he found himself using graph theoretic tools when covering contributions of billionaires to politi‐ cians.He explained the term “data journalism” to the class by way of ex‐ plaining his own data scientist profile.First of all, it involved lots of data visualization, because it’s a fast way of describing the bottom line of a dataset. Computer science skills are pretty important in data journalism, too. There are tight deadlines, and the data journalist has to be good with their tools and with messy data—because even federal data is messy. One has to be able to handle arcane formats, and often this means parsing stuff in Python. Jon himself uses JavaScript, Python, SQL, and MongoDB, among other tools.Statistics, Bruno says, informs the way you think about the world. It inspires you to write things: e.g., the average person on Twitter is a woman with 250 followers, but the median person has 0 followers— the data is clearly skewed. That’s an inspiration right there for a story.Bruno admits to being a novice in the field of machine learning. How‐ ever, he claims domain expertise as critical in data journalism: with exceptions for people who can specialize in one subject, say at a270 | Chapter 10: Social Networks and Data Journalismwww.finebook.ir
governmental office or a huge daily, for a smaller newspaper you need to be broad, and you need to acquire a baseline layer of expertise quickly.Of course communications and presentations are absolutely huge for data journalists. Their fundamental skill is translation: taking com‐ plicated stories and deriving meaning that readers will understand. They also need to anticipate questions, turn them into quantitative experiments, and answer them persuasively.Here’s advice from Jon for anyone initiating a data journalism project: don’t have a strong thesis before you interview the experts. Go in with a loose idea of what you’re searching for and be willing to change your mind and pivot if the experts lead you in a new and interesting direc‐ tion. Sounds kind of like exploratory data analysis!www.finebook.irData Journalism | 271
www.finebook.ir