---
title: "DSiR00"
author: "Robert A. Stevens"
date: "March 8, 2016"
output: html_document
---

**TODO:**

1. Finish outline

2. Add R code

3. Run R code and check

4. Do exercises

*Data Science in R: A Case Studies Approach to Computational Reasoning and Problem Solving*

by Deborah Nolan and Duncan Temple Lang

http://www.rdatasciencecases.org

# Chapter 3. Using Statistics to Identify Spam 

by Deborah Nolan and Duncan Temple Lang

## 3.1 Introduction

### 3.1.1 Computational Topics

## 3.2 Anatomy of an email Message

## 3.3 Reading the email Messages

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

## 3.4 Text Mining and Naive Bayes Classification

## 3.5 Finding the Words in a Message

### 3.5.1 Splitting the Message into Its Header and Body

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.5.2 Removing Attachments from the Message Body

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.5.3 Extracting Words from the Message Body

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.5.4 Completing the Data Preparation Process

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

## 3.6 Implementing the Naive Bayes Classifier

### 3.6.1 Test and Training Data

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.6.2 Probability Estimates from Training Data

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.6.3 Classifying New Messages

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

Figure 3.1: Boxplot of Log Likelihood Ratio for Spam and Ham. The log likelikhood ration, log(P(spam | message content)/P(ham | message content)), for 3116 test messages was computed using a naive Bayes approximation based on word frequencies found in manually classified training data. The test messages are grouped according to whether they are spam or ham. Notice most ham messages have value well below 0 and nearly all spam values are above 0.

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

Figure 3.2: Comparison of Type I and II Error Rates. The Type I and II error rates for the 3116 test messages are show as a function of the threshold tau. For example, with a threshold of tau = -43, all messages with an LLR value above -43 are classified as spam and those below as ham. In this case, 1% of ham is misclassified as spam and 2% of spam is misclassified as ham.

### 3.6.4 Computational Considerations

```{r, comment=NA}

```

## 3.7 Recursive Partitioning and Classification Trees

Figure 3.3: Example Tree from a Recursive Partition. This tree is a simple example of a recursive partition fitted model. It was fitted using the rpart() function and restricting the tree depth to 3 levels. The first yes-no question is whether the percentage of capitals in the message is less than 13. If not, the second question is whether there are fewer than 289 characters in the message. If the answer to this question is also no, then the next question is whether the message header contains an InReplyTo key. If the answer is again no, then the message is classified as spam. Of the 6232 messages in the training set, 77 ham and 643 spam fall into this leaf. The spam have been correctly classified and the 77 ham have been misclassified.

## 3.8 Organizing an email Message into an R Data Structure

### 3.8.1 Processing the Header

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.8.2 Processing Attachments

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.8.3 Testing Our Code on More email Data

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.8.4 Completing the Process

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

## 3.9 Deriving Variables from the email Message

Table 3.1: Variable Definition Table

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

### 3.9.1 Checking Our Code for Errors

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

Figure 3.4: Comparison of Two Measures of Length for a Message. This scatter plot shows the relationship between the number of lines and the number of characters in the body of a message. The plot is on log scale, and 1 is added to all of the values before taking logs to address issues with empty bodies. The line y = x is added for comparison purposes.

## 3.10 Exploring the email Feature Set

```{r, comment=NA}

```

Figure 3.5: Use of Capitalization in email. These boxplots compare the percentage of capital letters amoung all letters in a message body for spam and ham. The use of a log scale makes it easier to see that nearly 3/4 of the spam have more capital letters than nearly all of the ham.

```{r, comment=NA}

```

Figure 3.6: Comparison of the Amount of Capitaliation and the Size of the Message. This scatter plot examines the relationship between the percentage of capital letters among all letters in a message of the total number of characters in the message. Spam is marked by purple dots and ham by green. The darker color indictes overplotting. We see here that the spam tends to be longer and have more capital letters than ham.

```{r, comment=NA}

```

```{r, comment=NA}

```

Figure 3.7: Exploring Categorical Measures Derived from email. These two mosaic plots use area to denote the proportion of messages that fall in each category. The plot on the top shows those messages that have an "Re:" in the subject line tend not to be spam. The bottom plot shows that those messages that are from a user with a number at the end of their email address tend to be spam. However, few messagse are sent from such users so it is not clear how helpful this distinction will be in our classificaiton problem.

## 3.11 Fitting the rpart() Model to the email Data

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

Figure 3.8: Tree for Partitioning email to Predict Spam. This tree was fitted using rpart() on 6232 messages. The default values for all of the arguments to rpart() were used. Notice the leftmost leaf classified as ham those messages with fewer than 13% capitals, fewer than 4% HTML tags, and at least 1 forward. Eighteen spam messages fall into this leaf and so are misclassified, but 2240 of the ham is properly classified using these 3 yes-no questions.

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

```{r, comment=NA}

```

Figure 3.9: Type I and II Errors for Recursive Partitioning. This plot displays the Type I and II errors for predicting spam as a function of the size of the complexity parameters in the rpart() function. The complexity parameter is a mechanism for specifying the threshold for choosing a split for a subgroup. Splits that do not achieve a gain in fit of at least the size of the parameter value provided are not made. The Type I error is minimized at a complexity parameter value of 0.001 for an error rate of 3.9%. The Type II error rate for this complexity parameter value is 10.5% 

## 3.12 Exercises

Q.1

Q.2

Q.3

Q.4

Q.5

Q.6

Q.7

Q.8

Q.9

Q.10

Q.11

Q.12

Q.13

Q.14

Q.15

Q.16

Q.17

Q.18

Q.19

Q.20

Q.21

Q.22
